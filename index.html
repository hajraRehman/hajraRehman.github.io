<!-- Hero Section -->
<section id="one" class="wrapper spotlight style1">
  <div class="inner">
    <a href="#" class="image"><img src="https://via.placeholder.com/600x400/1a1a1a/ffffff?text=AI+Security" alt="Hafiza Hajrah Rehman" /></a>
    <div class="content">
      <h2 class="major">Hafiza Hajrah Rehman</h2>
      <p>Data Scientist | AI Security & Interpretability Specialist | M.Sc. @ Saarland University</p>
      <p>I build trustworthy, interpretable, and secure AI systems â€” from adversarial attacks to explainable models for healthcare and IoT.</p>
      <a href="#contact" class="special">Letâ€™s Connect</a>
    </div>
  </div>
</section>

<!-- Projects Section -->
<section id="two" class="wrapper alt style2">
  <section class="spotlight">
    <div class="image"><img src="https://raw.githubusercontent.com/hajraRehman/Membership-Inference-Attack-on-Resnet18/main/01_MIA.pt" alt="MIA Attack" /></div>
    <div class="content">
      <h2 class="major">ğŸ” Membership Inference Attack</h2>
      <p>Predicted membership confidence scores for private images using ResNet18 features + Random Forest. Achieved AUC=0.65 â€” well above random guessing.</p>
      <a href="https://github.com/hajraRehman/Membership-Inference-Attack-on-Resnet18" class="special">View Code</a>
    </div>
  </section>
  <section class="spotlight">
    <div class="image"><img src="https://via.placeholder.com/600x400/1a1a1a/ffffff?text=Model+Stealing" alt="Model Stealing" /></div>
    <div class="content">
      <h2 class="major">ğŸ•µï¸ Model Stealing via Mock API</h2>
      <p>Stole a protected encoder by querying its API, pre-training with SimCLR, and fine-tuning with augmented data. Replicated model with <5% accuracy loss.</p>
      <a href="https://github.com/hajraRehman/Model-Stealing-via-Mock-API" class="special">View Code</a>
    </div>
  </section>
  <section class="spotlight">
    <div class="image"><img src="https://raw.githubusercontent.com/hajraRehman/Explainability-Analysis-of-ResNet-Models-using-Network-Dissection-Grad-CAM-LIME/main/task2_outputs/n01443537_goldfish_vis_1.png" alt="XAI Analysis" /></div>
    <div class="content">
      <h2 class="major">ğŸ§¾ Explainability of ResNet</h2>
      <p>Compared Grad-CAM, LIME, and Network Dissection on ImageNet/Places365. Found IoU=0.3289 agreement â€” Grad-CAM most reliable for safety-critical apps.</p>
      <a href="https://github.com/hajraRehman/Explainability-Analysis-of-ResNet-Models-using-Network-Dissection-Grad-CAM-LIME" class="special">View Code</a>
    </div>
  </section>
</section>