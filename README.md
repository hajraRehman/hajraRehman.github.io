<div align="center">
  <img src="hajrahahah.jpg" width="150" alt="Hafiza Hajrah Rehman" style="border-radius: 50%; border: 3px solid #4A90E2; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">

  # Hafiza Hajrah Rehman
  <p><em><strong>Data Analyst | Data Scientist | AI Security & Interpretability Specialist | GenAI Enthusiast</strong></em></p>
  <p>📍 <strong>M.Sc. Data Science & AI @ Saarland University, Germany 🇩🇪</strong> | <strong>B.Sc. Computer Science @ UCP, Pakistan 🇵🇰</strong></p>

  <p>
    <a href="https://www.linkedin.com/in/hajrahrehman/">
      <img src="https://img.shields.io/badge/LinkedIn-Connect-0077B5?style=flat&logo=linkedin&logoColor=white" alt="LinkedIn">
    </a>
    <a href="https://github.com/hajraRehman">
      <img src="https://img.shields.io/badge/GitHub-Follow-181717?style=flat&logo=github&logoColor=white" alt="GitHub">
    </a>
    <a href="mailto:hafizahajra6@gmail.com">
      <img src="https://img.shields.io/badge/Email-Contact-D14836?style=flat&logo=gmail&logoColor=white" alt="Email">
    </a>
  </p>

  <br>
  <img src="https://img.shields.io/github/stars/hajraRehman?color=yellow&label=Stars" alt="GitHub Stars"> <img src="https://img.shields.io/github/forks/hajraRehman?color=green&label=Forks" alt="GitHub Forks">
</div>

---

## 📌 Quick Nav
- [👋 About Me](#👋-about-me)
- [🎓 Education](#🎓-education)
- [💼 Professional Experience](#💼-professional-experience)
- [🚀 Featured Projects](#🚀-featured-projects)
- [📁 Archived Projects](#📁-archived-&-conceptual-projects)
- [🏆 Achievements & Certifications](#🏆-achievements-and-certifications)
- [🤝 Leadership](#🤝-leadership-&-volunteering)
- [🛠️ Skills](#🛠️-technical-skills)
- [🌍 Languages](#🌍-languages)
- [📬 Connect](#📬-lets-connect)

---

## 👋 About Me
I'm Hafiza Hajrah Rehman, a dedicated **Data Scientist and AI Researcher** passionate about crafting **trustworthy, interpretable, and secure AI systems**. Currently pursuing my Master's in Data Science and Artificial Intelligence at Saarland University, Germany, I blend rigorous theory with practical innovation in areas like adversarial machine learning, explainable AI (XAI), and efficient LLM fine-tuning.

From my roots in Pakistan to thriving in Germany's tech ecosystem, I excel at turning complex data into ethical, impactful solutions—whether hardening models against attacks, visualizing "what models see," or optimizing for low-resource domains like healthcare and IoT. As a mentor and community leader, I believe in accessible AI that empowers everyone.

> *"I believe in code that works, reports that explain, and models that can be trusted."*

Fluent in English, building German fluency, and always open to collaborations in **AI Research, ML Engineering, or Trustworthy AI** (with a secret NASA dream 🚀). Let's innovate responsibly!

---

## 🎓 Education

### M.Sc. Data Science and Artificial Intelligence  
**Saarland University**, Saarbrücken, Germany  
*March 2024 – March 2026 (Expected)*  
- **Key Courses**: Machine Learning, Neural Networks: Theory and Implementation, Generative AI, Statistical NLP, Advances in AI for Autonomous Driving, German as a Foreign Language A1  

### B.Sc. Computer Science (Honors)  
**University of Central Punjab**, Lahore, Pakistan  
*December 2019 – July 2023*  
- **Final Year Project**: Deep Learning for Pedestrian Danger Estimation (3rd Place in University Competition)  
- **Relevant Coursework**: Artificial Intelligence, Data Analysis Techniques, Mathematics for Machine Learning, Introduction to Data Science  

---

## 💼 Professional Experience

### ML/Data Analyst  
**Zeeoutsourcing UK** (Remote)  
*November 2022 – February 2024*  
- Contributed to ongoing AI research projects focused on IoT security and energy-efficient intrusion detection.  
- Worked on the development of SFlexCrypt, a framework for detecting Sinkhole attacks in wireless sensor networks using machine learning.  
- Performed data preprocessing, model training, and evaluation on the Contiki-Cooja dataset to improve detection accuracy and energy efficiency.  
- Collaborated with the research team to analyze results and support publications on IoT-based security and power optimization in smart city applications.  

### AI Engineering Intern  
**Zeeoutsourcing UK** (Remote)  
*August 2022 – October 2022*  
- Assisted in ML model development for IoT applications, focusing on performance tuning and evaluation.  
- Contributed to literature review and data preparation for energy-efficient IoT systems.  
- Assisted in documentation, result visualization, and report preparation for research publications.  

---

## 🚀 Featured Projects

Dive into my hands-on work in AI security, interpretability, and healthcare. Each project includes code, demos, and insights—fork away!

| Project | Description | Tech Stack | Links |
|---------|-------------|------------|-------|
| **🔐 Membership Inference Attack (MIA) on ResNet18**<br/>*Evaluating Privacy Leakage in Pretrained Models* | Shadow model training + attack classifier to detect training set membership. >80% success on CIFAR-10 subset, spotlighting privacy risks. | PyTorch, CIFAR-10, Adversarial ML | [![View Code](https://img.shields.io/badge/View_Code-black?style=flat&logo=github&logoColor=white)](https://github.com/hajraRehman/Membership-Inference-Attack-on-Resnet18) |
| **🕵️ Model Stealing via Mock API**<br/>*Reverse-Engineering a Protected Encoder* | Black-box extraction with query synthesis + fine-tuning; replicated model with <5% accuracy loss, exposing API flaws. | PyTorch, Transfer Learning, API Security | [![View Code](https://img.shields.io/badge/View_Code-black?style=flat&logo=github&logoColor=white)](https://github.com/hajraRehman/Model-Stealing-via-Mock-API) |
| **🛡️ Robust Adversarial Training for CIFAR-10**<br/>*Building Models That Survive Attacks* | FGSM/PGD hardening on ResNet18: 0% → 48% robust accuracy under PGD, 78% clean—balancing defense & generalization. | PyTorch, FGSM, PGD, Model Defense | [![View Code](https://img.shields.io/badge/View_Code-black?style=flat&logo=github&logoColor=white)](https://github.com/hajraRehman/Robust-Adversarial-Training-for-CIFAR-10) |
| **🧾 Interpretability of ResNet using Grad-CAM & Network Dissection**<br/>*What Does Your Model Actually “See”?* | Neuron activation mapping on ImageNet/Places365; Grad-CAM/LIME visuals for transparent decisions in critical apps. | XAI, Grad-CAM, LIME, OpenCV | [![View Visuals](https://img.shields.io/badge/View_Visuals-blue?style=flat&logo=figma&logoColor=white)](https://hafizahajrah.notion.site/ResNet-Interpretability-Demo) [![View Code](https://img.shields.io/badge/View_Code-black?style=flat&logo=github&logoColor=white)](https://github.com/hajraRehman/Explainability-Analysis-of-ResNet-Models
